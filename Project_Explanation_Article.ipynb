{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI-Powered Financial Analysis: Multi-Agent LLM Systems Transform Data into Insights\n",
    "\n",
    " \n",
    "Batuhan Sener\n",
    "12 min read\n",
    "Jul 30, 2024\n",
    " \n",
    "Financial Agents with GPT-4o-mini and LLaMA 3.1 and more … Click here to explore …\n",
    "This article shares the experiences of developing a multi-agent LLM system that gathers relevant information from the internet, performs sentiment analysis on comments from Reddit, conducts fundamental and technical analysis, and summarizes the information about stock, using a language model. The system is made accessible through Streamlit.\n",
    "Overview of Essential Technologies and Frameworks\n",
    "Before starting the project, I would like to talk about the technologies and frameworks I used in this project:\n",
    "•\t1-) CrewAI : Multi-agent system.\n",
    "•\t2-) Langchain : Tools & model usage.\n",
    "•\t3-) Reddit(praw) & Yahoo Finance(yfinance): Data collecting.\n",
    "•\t4-) Hugging Face : Finetuned sentiment model for finance.\n",
    "•\t5-) Groq Cloud and OpenAI : Accessing LLama and GPT models.\n",
    "•\t6-) Streamlit : UI & Deployment.\n",
    "Explaining Crew AI and How I Used It\n",
    "Crew AI is a collaborative working system designed to enable various artificial intelligence agents to work together as a team, efficiently accomplishing complex tasks.\n",
    "Includes crew ai agent tasks and tools.\n",
    "Agents :Each agent is an AI unit that takes on a specific role and works according to that role. Every agent is designed to achieve a specific goal and can perform certain tasks.\n",
    "Tasks: Tasks are specific assignments that agents need to complete, along with instructions on how to complete them. Tasks define the expected outcomes and the tools that will be used.\n",
    "Tools: Tools are additional resources and integrations that agents can use while performing their tasks. These tools provide functions like data collection, analysis, or access to specific APIs.\n",
    "In this project, I integrated Meta and OpenAI’s language models. I created custom tools and developed agents such as Researcher, Technical and Fundamental Analyst, and Reporter to gather stock information. I will share my experiences with this crew system.\n",
    "Explaining Langchain and How I Used It\n",
    "LangChain is an open-source framework for building applications based on large language models (LLMs). It provides tools and abstractions to customize, improve the accuracy, and relevance of the information generated by the models. Developers can use LangChain components to create new prompt chains or customize existing templates. LangChain also allows LLMs to access new data sets without retraining.\n",
    "In this project, I used the YahooFinanceNewsTool for stock information and accessed Groq and OpenAI models.\n",
    "Data Collecting from Reddit and Yahoo Finance\n",
    "PRAW (Python Reddit API Wrapper) is a library used for easy access to Reddit’s API. PRAW provides a user-friendly interface for fetching Reddit data, browsing subreddits, creating posts and comments, and interacting with Reddit.\n",
    "YFINANCE is a Python library used to fetch financial data from Yahoo Finance. It allows you to easily obtain various financial data such as stock prices, historical data, financial reports, and other financial information.\n",
    "In this project, I used yfinance to collect data for fundamental and technical analysis and for visualization. I used praw to fetch data from Reddit to analyze users’ opinions about the stock from the ‘wallstreetbets’, ‘stocks’, and ‘investing’ subreddits.\n",
    "Explaining Hugging Face and How I Used It\n",
    "Hugging Face is a company and an open-source platform that provides tools and resources for building, training, and deploying machine learning models. The Hugging Face Hub hosts many models for a variety of machine learning tasks.\n",
    "In this project, I used the Hugging Face model “distilroberta-finetuned-financial-news-sentiment-analysis” to analyze the sentiment of data from Reddit.\n",
    "Groq and OpenAI\n",
    "Groq is a technology company that develops innovative hardware and software solutions for machine learning and artificial intelligence. Their products are designed to provide high-performance, low-latency computing for complex AI workloads.\n",
    "In this project, I integrated GPT-4o, GPT-4o-mini, LLaMA 3 8B, LLaMA 3.1 8B, and LLaMA 3.1 70B language models from Groq Cloud and OpenAI Platform.\n",
    "Streamlit UI and Cloud\n",
    "Streamlit is an open-source framework used for creating interactive web applications specifically for machine learning, data science and LLM projects. Streamlit Cloud is a platform for deploying, managing, and sharing applications directly from GitHub repository.\n",
    "In my project, I used Streamlit to create an interactive interface and deployed it on Streamlit Cloud.\n",
    "Steps Covered in this Tutorial\n",
    "The steps to be examined for the multi-agent system:\n",
    "•\tCustom Tools for Financial Analysis\n",
    "•\tDefining the Crew\n",
    "•\tDeveloping the Streamlit Application & Deployment the App\n",
    "•\tProject Usage and Output\n",
    "To keep the article concise, I will not delve into the detailed explanation of all the code. For more information, feel free to contact me. My contact details will be shared at the end of the page.\n",
    "1- Custom Tools for Financial Analysis\n",
    "Tools are specialized components that agents can use to perform specific tasks more effectively. These tools can provide various functions such as data collection, analysis, interaction with APIs, or accessing specific resources. You can even integrate it with Langchain tools.\n",
    "In this article, I will explain the Sentiment tool, but I will also include descriptions of the other tools I used.\n",
    "•\tBrowser Tool: Implementing web browsing functionality.\n",
    "•\tSearch Tools: Developing specific search operations with SERPER.\n",
    "•\tSentiment Analysis Tool: Building a tool to analyze sentiment in financial data.\n",
    "•\tFundamental Analysis Tool: Creating a tool for fundamental stock analysis using Yahoo Finance.\n",
    "•\tYahooFinanceNewsTool: Gathering and analyzing stock-related news from Langchain’s tool.\n",
    "•\tTech Analysis Tool: Implementing technical stock analysis using Yahoo Finance.\n",
    "\n",
    "Sentiment Analysis Tool :\n",
    "First I loads the model and tokenizer from the transformers library for sentiment analysis. The analyze_sentiment function then performs sentiment analysis on given text and returns the result as \"negative,\" \"neutral,\" or \"positive.\" The get_reddit_posts function retrieves posts containing a specific stock symbol from a particular subreddit. Using the praw library, it connects to the Reddit API and fetches the posts. These posts are filtered to include only those from the last 30 days. The ‘ @ tool’ decorator allows the function to be used as a CrewAI tool. The reddit_sentiment_analysis function performs sentiment analysis on posts from specified subreddits about a stock symbol and returns the count of each sentiment label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_analysis_tool.py\n",
    "import os\n",
    "import praw\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from crewai_tools import tool\n",
    "\n",
    "# Download hf model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of a given text.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    scores = outputs.logits.softmax(dim=1).detach().numpy()[0]\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    label = labels[scores.argmax()]\n",
    "    return label\n",
    "\n",
    "def get_reddit_posts(subreddit_name, stock_symbol, limit=100, days=30):\n",
    "    \"\"\"\n",
    "    Get posts from a specific subreddit containing the stock symbol within the last specified days.\n",
    "    \"\"\"\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "        client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "        user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "    )\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    end_date = datetime.utcnow()\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "    \n",
    "    posts = []\n",
    "    for post in subreddit.search(stock_symbol, sort='new', time_filter='month', limit=limit):\n",
    "        post_date = datetime.utcfromtimestamp(post.created_utc)\n",
    "        if start_date <= post_date <= end_date:\n",
    "            posts.append(post.title)\n",
    "    return posts\n",
    "\n",
    "@tool\n",
    "def reddit_sentiment_analysis(stock_symbol: str, subreddits: list = ['wallstreetbets', 'stocks', 'investing'], limit: int = 100):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on posts from specified subreddits about a stock symbol.\n",
    "    \n",
    "    Args:\n",
    "        stock_symbol (str): The stock symbol to search for.\n",
    "        subreddits (list): List of subreddits to search in.\n",
    "        limit (int): Number of posts to fetch from each subreddit.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of sentiment labels for each post.\n",
    "    \"\"\"\n",
    "    all_sentiments = []\n",
    "    sentiments_counts={'neutral': 0, 'negative': 0, 'positive': 0}\n",
    "    \n",
    "    for subreddit in subreddits:\n",
    "        posts = get_reddit_posts(subreddit, stock_symbol, limit)\n",
    "        for post in posts:\n",
    "            sentiment = analyze_sentiment(post)\n",
    "            all_sentiments.append((sentiment))\n",
    "            sentiments_counts[sentiment]+=1\n",
    "\n",
    "    return sentiments_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Crew\n",
    "For model selection, I created a function called initialize_llm using LLaMA or OpenAI, and wrote the create_crew function to define the tools to be used. I defined Agents and Tasks. When creating agents, I ensured clear goals and detailed background information to make them more capable and specific. For tasks, I provided clear instructions and expected outputs to make them more understandable and achievable. Using the Crew class, I integrated all agents and tasks to form and start the team. Finally, I saved the results to a file and returned them to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool, WebsiteSearchTool\n",
    "from tools.sentiment_analysis_tool import reddit_sentiment_analysis\n",
    "from tools.yf_tech_analysis_tool import yf_tech_analysis\n",
    "from tools.yf_fundamental_analysis_tool import yf_fundamental_analysis\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Environment Variables\n",
    "load_dotenv()\n",
    "os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")\n",
    "os.environ[\"REDDIT_CLIENT_ID\"] = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "os.environ[\"REDDIT_CLIENT_SECRET\"] = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "os.environ[\"REDDIT_USER_AGENT\"] = os.getenv(\"REDDIT_USER_AGENT\")\n",
    "\n",
    "# Model Selection\n",
    "def initialize_llm(model_option, openai_api_key, groq_api_key):\n",
    "    if model_option == 'OpenAI GPT-4o':\n",
    "        return ChatOpenAI(openai_api_key=openai_api_key, model='gpt-4o', temperature=0.1)\n",
    "    elif model_option == 'OpenAI GPT-4o Mini':\n",
    "        return ChatOpenAI(openai_api_key=openai_api_key, model='gpt-4o-mini', temperature=0.1)\n",
    "    elif model_option == 'Llama 3 8B':\n",
    "        return ChatGroq(groq_api_key=groq_api_key, model='llama3-8b-8192', temperature=0.1)\n",
    "    elif model_option == 'Llama 3.1 70B':\n",
    "        return ChatGroq(groq_api_key=groq_api_key, model='llama-3.1-70b-versatile', temperature=0.1)\n",
    "    elif model_option == 'Llama 3.1 8B':\n",
    "        return ChatGroq(groq_api_key=groq_api_key, model='llama-3.1-8b-instant', temperature=0.1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model option selected\")\n",
    "\n",
    "\n",
    "def create_crew(stock_symbol, model_option, openai_api_key, groq_api_key):\n",
    "    llm = initialize_llm(model_option, openai_api_key, groq_api_key)\n",
    "    # Tools Initialization\n",
    "    reddit_tool = reddit_sentiment_analysis\n",
    "    serper_tool = SerperDevTool()\n",
    "    yf_tech_tool = yf_tech_analysis\n",
    "    yf_fundamental_tool = yf_fundamental_analysis\n",
    "\n",
    "    # Agents Definitions\n",
    "    researcher = Agent(\n",
    "        role='Senior Stock Market Researcher',\n",
    "        goal='Gather and analyze comprehensive data about {stock_symbol}',\n",
    "        verbose=True,\n",
    "        memory=True,\n",
    "        backstory=\"With a Ph.D. in Financial Economics and 15 years of experience in equity research, you're known for your meticulous data collection and insightful analysis.\",\n",
    "        tools=[reddit_tool, serper_tool, YahooFinanceNewsTool()],\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    technical_analyst = Agent(\n",
    "        role='Expert Technical Analyst',\n",
    "        goal='Perform an in-depth technical analysis on {stock_symbol}',\n",
    "        verbose=True,\n",
    "        memory=True,\n",
    "        backstory=\"As a Chartered Market Technician (CMT) with 15 years of experience, you have a keen eye for chart patterns and market trends.\",\n",
    "        tools=[yf_tech_tool],\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    fundamental_analyst = Agent(\n",
    "        role='Senior Fundamental Analyst',\n",
    "        goal='Conduct a comprehensive fundamental analysis of {stock_symbol}',\n",
    "        verbose=True,\n",
    "        memory=True,\n",
    "        backstory=\"With a CFA charter and 15 years of experience in value investing, you dissect financial statements and identify key value drivers.\",\n",
    "        tools=[yf_fundamental_tool],\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    reporter = Agent(\n",
    "        role='Chief Investment Strategist',\n",
    "        goal='Synthesize all analyses to create a definitive investment report on {stock_symbol}',\n",
    "        verbose=True,\n",
    "        memory=True,\n",
    "        backstory=\"As a seasoned investment strategist with 20 years of experience, you weave complex financial data into compelling investment narratives.\",\n",
    "        tools=[reddit_tool, serper_tool, yf_fundamental_tool, yf_tech_tool, YahooFinanceNewsTool()],\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Task Definitions\n",
    "    research_task = Task(\n",
    "        description=(\n",
    "            \"Conduct research on {stock_symbol}. Your analysis should include:\\n\"\n",
    "            \"1. Current stock price and historical performance (5 years).\\n\"\n",
    "            \"2. Key financial metrics (P/E, EPS growth, revenue growth, margins).\\n\"\n",
    "            \"3. Recent news and press releases (1 month).\\n\"\n",
    "            \"4. Analyst ratings and price targets (min 3 analysts).\\n\"\n",
    "            \"5. Reddit sentiment analysis (100 posts).\\n\"\n",
    "            \"6. Major institutional holders and recent changes.\\n\"\n",
    "            \"7. Competitive landscape and {stock_symbol}'s market share.\\n\"\n",
    "            \"Use reputable financial websites for data.\"\n",
    "        ),\n",
    "        expected_output='A detailed 150-word research report with data sources and brief analysis.',\n",
    "        agent=researcher\n",
    "    )\n",
    "\n",
    "    technical_analysis_task = Task(\n",
    "        description=(\n",
    "            \"Perform technical analysis on {stock_symbol}. Include:\\n\"\n",
    "            \"1. 50-day and 200-day moving averages (1 year).\\n\"\n",
    "            \"2. Key support and resistance levels (3 each).\\n\"\n",
    "            \"3. RSI and MACD indicators.\\n\"\n",
    "            \"4. Volume analysis (3 months).\\n\"\n",
    "            \"5. Significant chart patterns (6 months).\\n\"\n",
    "            \"6. Fibonacci retracement levels.\\n\"\n",
    "            \"7. Comparison with sector's average.\\n\"\n",
    "            \"Use the yf_tech_analysis tool for data.\"\n",
    "        ),\n",
    "        expected_output='A 100-word technical analysis report with buy/sell/hold signals and annotated charts.',\n",
    "        agent=technical_analyst\n",
    "    )\n",
    "\n",
    "    fundamental_analysis_task = Task(\n",
    "        description=(\n",
    "            \"Conduct fundamental analysis of {stock_symbol}. Include:\\n\"\n",
    "            \"1. Review last 3 years of financial statements.\\n\"\n",
    "            \"2. Key ratios (P/E, P/B, P/S, PEG, Debt-to-Equity, etc.).\\n\"\n",
    "            \"3. Comparison with main competitors and industry averages.\\n\"\n",
    "            \"4. Revenue and earnings growth trends.\\n\"\n",
    "            \"5. Management effectiveness (ROE, capital allocation).\\n\"\n",
    "            \"6. Competitive advantages and market position.\\n\"\n",
    "            \"7. Growth catalysts and risks (2-3 years).\\n\"\n",
    "            \"8. DCF valuation model with assumptions.\\n\"\n",
    "            \"Use yf_fundamental_analysis tool for data.\"\n",
    "        ),\n",
    "        expected_output='A 100-word fundamental analysis report with buy/hold/sell recommendation and key metrics summary.',\n",
    "        agent=fundamental_analyst\n",
    "    )\n",
    "\n",
    "    report_task = Task(\n",
    "        description=(\n",
    "            \"Create an investment report on {stock_symbol}. Include:\\n\"\n",
    "            \"1. Executive Summary: Investment recommendation.\\n\"\n",
    "            \"2. Company Snapshot: Key facts.\\n\"\n",
    "            \"3. Financial Highlights: Top metrics and peer comparison.\\n\"\n",
    "            \"4. Technical Analysis: Key findings.\\n\"\n",
    "            \"5. Fundamental Analysis: Top strengths and concerns.\\n\"\n",
    "            \"6. Risk and Opportunity: Major risk and growth catalyst.\\n\"\n",
    "            \"7. Reddit Sentiment: Key takeaway from sentiment analysis, including the number of positive, negative and neutral comments and total comments.\\n\"\n",
    "            \"8. Investment Thesis: Bull and bear cases.\\n\"\n",
    "            \"9. Price Target: 12-month forecast.\\n\"\n",
    "        ),\n",
    "        expected_output='A 600-word investment report with clear sections, key insights.',\n",
    "        agent=reporter\n",
    "    )\n",
    "\n",
    "    # Crew Definition and Kickoff for Result\n",
    "    crew = Crew(\n",
    "        agents=[researcher, technical_analyst, fundamental_analyst, reporter],\n",
    "        tasks=[research_task, technical_analysis_task, fundamental_analysis_task, report_task],\n",
    "        process=Process.sequential,\n",
    "        cache=True\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff(inputs={'stock_symbol': stock_symbol})\n",
    "\n",
    "    os.makedirs('./crew_results', exist_ok=True)\n",
    "    file_path = f\"./crew_results/crew_result_{stock_symbol}.md\"\n",
    "    result_str = str(result)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(result_str)\n",
    "    \n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing the Streamlit Application & Deployment the App\n",
    "I created an interactive area that allows the user to select a model, integrates API keys for model usage, and generates charts using Yahoo Finance data. The multi-agent system performs all the steps and displays the outputs on the screen. Afterwards, I uploaded the code to GitHub and integrated it with Streamlit Cloud. To keep this article concise, I am concluding the explanation here. For a more detailed code review, please contact me privately.\n",
    "\n",
    "Project Usage and Output\n",
    "•\tFirst, select the model you want to use.\n",
    "•\tTo run the project, you need to obtain an API key based on the model you select. I have shared a link on how you can access Groq and OpenAI APIs.\n",
    "•\tEnter the stock symbol you are interested in for a detailed analysis like (NVDA, AAPL, ACN)\n",
    "•\tFor interactive charts, select the time period and indicators, then click the “Analyze Stock” button.\n",
    "The model will then gather data about the selected stock from the internet and provide you with an analysis based on various parameters, including fundamental and technical analysis outputs and sentiment results, according to the template of the chosen model.\n",
    "Overview :\n",
    " \n",
    " \n",
    "Output :\n",
    "Stock Information\n",
    "Company Name: NVIDIA Corporation\n",
    "Sector: Technology\n",
    "Industry: Semiconductors\n",
    "Country: United States\n",
    "Current Price: $103.73\n",
    "Market Cap: $2551581769728\n",
    "Analysis Result\n",
    "\n",
    "NVIDIA Corporation (NVDA) Investment Report\n",
    "\n",
    "1. Executive Summary: Investment Recommendation NVIDIA Corporation (NVDA) is a leading player in the semiconductor industry, particularly known for its graphics processing units (GPUs) that power gaming, AI, and data center applications. Given its robust financial health, strong growth metrics, and competitive positioning, the recommendation is to Hold. While the stock appears oversold, it shows potential for recovery amidst current bearish trends.\n",
    "\n",
    "2. Company Snapshot: Key Facts\n",
    "\n",
    "Company Name: NVIDIA Corporation\n",
    "Sector: Technology\n",
    "Industry: Semiconductors\n",
    "Market Cap: $2.55 trillion\n",
    "P/E Ratio: 60.66\n",
    "PEG Ratio: 0.89\n",
    "Debt to Equity Ratio: 22.87\n",
    "3. Financial Highlights: Top Metrics and Peer Comparison NVIDIA's financial performance is characterized by:\n",
    "\n",
    "Revenue Growth (YoY): 25.85%\n",
    "Net Income Growth (YoY): 58.13%\n",
    "Gross Margin: 75.29%\n",
    "Operating Margin: 64.93%\n",
    "Net Profit Margin: 53.40% Compared to peers, NVDA's high P/E ratio indicates strong growth expectations, while its low PEG ratio suggests it may be undervalued relative to its growth potential.\n",
    "4. Technical Analysis: Key Findings\n",
    "\n",
    "Current Price: $103.73\n",
    "20-Day Moving Average: $122.04\n",
    "50-Day Moving Average: $119.38\n",
    "RSI: 21.04 (indicating oversold conditions)\n",
    "MACD: Bearish\n",
    "Support Level: $102.54\n",
    "Resistance Level: $136.15 The technical indicators suggest a bearish breakdown, but the stock is currently oversold, indicating a potential for a price rebound.\n",
    "5. Fundamental Analysis: Top Strengths and Concerns Strengths:\n",
    "\n",
    "Strong revenue and net income growth rates.\n",
    "Low debt-to-equity ratio, indicating financial stability.\n",
    "High gross and operating margins, reflecting efficient operations.\n",
    "Concerns:\n",
    "\n",
    "High P/E ratio may indicate overvaluation.\n",
    "Current bearish trends in the market could impact short-term performance.\n",
    "6. Risk and Opportunity: Major Risk and Growth Catalyst Major Risk: The semiconductor industry is highly cyclical and sensitive to economic downturns, which could adversely affect NVDA's sales and profitability.\n",
    "\n",
    "Growth Catalyst: The increasing demand for AI and machine learning applications presents a significant growth opportunity for NVIDIA, as its GPUs are essential for these technologies.\n",
    "\n",
    "7. Reddit Sentiment: Key Takeaway from Sentiment Analysis From the sentiment analysis conducted on Reddit:\n",
    "\n",
    "Total Comments Analyzed: 100\n",
    "Positive Comments: 3\n",
    "Negative Comments: 6\n",
    "Neutral Comments: 24 The sentiment is predominantly neutral, with a slight inclination towards negativity, reflecting cautious investor sentiment amidst current market conditions.\n",
    "8. Investment Thesis: Bull and Bear Cases Bull Case: If NVIDIA continues to capitalize on the growing AI market and maintains its competitive edge, it could see substantial revenue growth, leading to a higher stock price.\n",
    "\n",
    "Bear Case: Economic headwinds and increased competition in the semiconductor space could lead to declining sales and profitability, negatively impacting the stock price.\n",
    "\n",
    "9. Price Target: 12-Month Forecast Considering the current market conditions and NVDA's growth potential, a conservative 12-month price target is set at $130, reflecting a recovery from current oversold levels and aligning with historical performance trends.\n",
    "\n",
    "In conclusion, while NVIDIA Corporation presents a compelling investment opportunity due to its strong fundamentals and growth potential, investors should remain cautious given the current market sentiment and technical indicators. A hold position is recommended until clearer bullish signals emerge.\n",
    "\n",
    "Conclusion and Recommendations\n",
    "•\tIt is not investment advice. Just personal hobby :)\n",
    "•\tIt’s important to keep the descriptions for Agents and Tasks short and concise. Long and detailed descriptions can exceed the Tokens-per-Minute (TPM) limit and be very costly.\n",
    "•\tBefore creating the fundamental and technical analysis tools, I was completing tasks by fetching all the data from the internet. This resulted in a high processing load, so I created custom tools to meet this need. This approach is more cost-effective. It’s important to assess needs properly.\n",
    "•\tGPT models have shown better inferences compared to LLaMA models. GPT-4o-mini is very functional. It has a higher TPM limit compared to GPT-4, and the results are good. It’s a more cost-effective model.\n",
    "References\n",
    "Reddit (wallstreetbets, stocks, investing)\n",
    "Yahoo Finance\n",
    "CrewAI Docs\n",
    "Streamlit Docs\n",
    "Langchain Tools\n",
    "You can use the link to try the project\n",
    "All codes are my Github\n",
    "If you would like to consult or get in touch, you can reach me via LinkedIn or email.\n",
    "If you enjoy my content, please consider showing your support by clapping for my articles or buying me a coffee. Your support is greatly appreciated.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
